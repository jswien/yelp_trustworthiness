{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Trustworthiness Classifier\n",
    "\n",
    "Jason Wien   \n",
    "September-October 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this notebook we train a model to identify untrustworthy Yelp reviews. We use a \"one vs rest\" classification scheme to identify reviews that are **>1** star over the mean or **<-0.5** stars under the mean (outside the upper and lower quartiles).  \n",
    "\n",
    "The strategy we use is to first use a pre-trained word2vec model to embed each word into a 300 dimensional vector space. For each review, we take only the first 400 words and so each instance can be thought of as a one dimensional sequence of vectors. \n",
    "\n",
    "We then train a one dimensional CNN to determine the trustworthiness of a review from this sequence. As reviews that are over the mean and under the mean have different characteristics that make the untrustworthy, we train two different classifiers on each of these groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import LSTM, Conv1D, Dropout, Dense, Flatten, MaxPooling1D, Input\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Data\n",
    "\n",
    "First we import a random training and test set from the full dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_reviews = 2396491\n",
    "N_train = 30000\n",
    "N_test = 10000\n",
    "\n",
    "skip = sorted(random.sample(range(1,N_reviews),N_reviews - (N_train + N_test)))\n",
    "df = pd.read_csv('review_deviations.csv',skiprows=skip, index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at how the deviations are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    40000.000000\n",
       "mean        -0.010425\n",
       "std          1.225731\n",
       "min         -4.000000\n",
       "25%         -0.500000\n",
       "50%          0.500000\n",
       "75%          1.000000\n",
       "max          4.000000\n",
       "Name: deviation, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['deviation'].hist(bins=15)\n",
    "df['deviation'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values -0.5 and 1.0 mark the lower and upper quartiles of the dataset, and so that is how we choose our cutoffs for trustworthiness.\n",
    "\n",
    "Next we define convenient functions to encode our \"under\" or \"over\" parameters. Trustworthy reviews get a score of 0, while scores that are over or under the mean get a score of $\\pm 1$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_score(x):\n",
    "    if x<-0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def over_score(x):\n",
    "    if x>1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def score(x):\n",
    "    if x<-0.5:\n",
    "        return -1\n",
    "    elif x>1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reviews are of all different word lengths, so we convert review to a sequence of vectors of fixed length. We choose **400** words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 400\n",
    "n_word_vec = len(nlp('hello').vector)\n",
    "\n",
    "def review_to_vec_seq(review):\n",
    "    vec_seq = np.array([word.vector for word in nlp(review)])\n",
    "    if len(vec_seq) < max_words:\n",
    "        return(np.concatenate((vec_seq, np.zeros((max_words-vec_seq.shape[0],n_word_vec)))))\n",
    "    else:\n",
    "        return(vec_seq[:max_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we want to have a low false positive rate, so we will skew the distribution of the training data for each classifier appropriately. That is, in general we can break up the loss function as a sum over positive and negative training instances. Let $\\overline \\ell _p$ and $\\overline \\ell_n$ be the average loss on positive and negative instances respectively. Therefore we can write the total loss as\n",
    "\n",
    "$$ \\mathscr L = N_p \\overline \\ell_p + N_n \\overline \\ell_n\\, , $$\n",
    "\n",
    "where $N_p$ and $N_n$ are the number of positive and negative instances respectively. We can think of $N_p$ and $N_n$ then as weights determining how much we should penalize a high loss on positive and negative instances. Therefore, if we want to penalize misclassifying negative instances more than misclassifying positive instances (i.e. penalize false positives more than false negatives), we should have $N_n > N_p$. Note that this approach is equivalent to weighting the loss function differently for positive and negative instances.\n",
    "\n",
    "To do so we first have to separate our training data by score. We order the training instances by the deviation, then find the border between negative, neutral, and positive instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.iloc[:N_train].sort_values('deviation')\n",
    "\n",
    "neg_neut_border = len(df_train[df_train['deviation'] < -0.5])\n",
    "neut_pos_border = len(df_train[df_train['deviation'] <= 1])\n",
    "\n",
    "n_neg = neg_neut_border\n",
    "n_neut = neut_pos_border-neg_neut_border\n",
    "n_pos = N_train - neut_pos_border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24 , 0.658, 0.102])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round((n_neg / N_train, n_neut/N_train, n_pos/N_train),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the \"under\" classifier we use a 2:1 ratio of negatives to positives, and for the \"over\" classifier we use a 3:1 ratio (which we decided through experimentation). The desired target is to use 10000 instances to train each classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_base = min(3333,int((n_neut+n_pos)/2), int(n_neg))\n",
    "under_draws = random.sample(range(neg_neut_border),under_base+1)+random.sample(range(neg_neut_border,N_train),2*under_base)\n",
    "\n",
    "over_base = min(2500,int((n_neut+n_neg)/3),int(n_pos))\n",
    "over_draws = random.sample(range(neut_pos_border),3*over_base)+random.sample(range(neut_pos_border,N_train),over_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(under_draws), len(over_draws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we build the training and test sets to use for the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over = df_train.iloc[over_draws]['text'].apply(review_to_vec_seq).values\n",
    "X_over = np.array([x for x in X_over])\n",
    "\n",
    "X_under = df_train.iloc[under_draws]['text'].apply(review_to_vec_seq).values\n",
    "X_under = np.array([x for x in X_under])\n",
    "\n",
    "Y_over = df_train.iloc[over_draws]['deviation'].apply(over_score).values\n",
    "Y_under = df_train.iloc[under_draws]['deviation'].apply(under_score).values\n",
    "Y_train = df_train['deviation'].apply(score).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.iloc[N_train:]\n",
    "X_test = df_test['text'].apply(review_to_vec_seq).values\n",
    "\n",
    "X_test = np.array([x for x in X_test])\n",
    "\n",
    "Y_test_over = df_test['deviation'].apply(over_score).values\n",
    "Y_test_under = df_test['deviation'].apply(under_score).values\n",
    "Y_test = df_test['deviation'].apply(score).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Classifiers\n",
    "\n",
    "Each classifier consists of two convolutional layers with max pooling, one fully connected layer, and an output layer. Additionally, we introduce two droput layers to prevent overfitting. We use 20 epochs to train each classifier, as after that the loss starts to level out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 400, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 400, 64)           57664     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 200, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 200, 32)           6176      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 100, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 150)               480150    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 544,141\n",
      "Trainable params: 544,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "over_input = Input((max_words, n_word_vec))\n",
    "over_conv1 = Conv1D(64, 3, padding = \"same\", activation='relu')(over_input)\n",
    "over_pool1 = MaxPooling1D(pool_size=2)(over_conv1)\n",
    "over_conv2 = Conv1D(32, 3, padding = \"same\", activation='relu')(over_pool1)\n",
    "over_pool2 = MaxPooling1D(pool_size=2)(over_conv2)\n",
    "over_flatten = Flatten()(over_pool2)\n",
    "over_drop1 = Dropout(0.2)(over_flatten)\n",
    "over_dense1 = Dense(150, activation ='relu')(over_drop1)\n",
    "over_drop2 = Dropout(0.2)(over_dense1)\n",
    "over_out = Dense(1, activation ='sigmoid')(over_drop2)\n",
    "\n",
    "model_over = Model(inputs = over_input, outputs = over_out)\n",
    "model_over.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model_over.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 99s 10ms/step - loss: 0.5635 - acc: 0.7388\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 73s 7ms/step - loss: 0.5263 - acc: 0.7500\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 76s 8ms/step - loss: 0.4993 - acc: 0.7504\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 74s 7ms/step - loss: 0.4846 - acc: 0.7564\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 76s 8ms/step - loss: 0.4439 - acc: 0.7745\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 77s 8ms/step - loss: 0.3995 - acc: 0.8033\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 78s 8ms/step - loss: 0.3647 - acc: 0.8272\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 75s 8ms/step - loss: 0.3290 - acc: 0.8537\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 75s 8ms/step - loss: 0.2754 - acc: 0.8770\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 74s 7ms/step - loss: 0.2347 - acc: 0.8999\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 75s 7ms/step - loss: 0.2017 - acc: 0.9159\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 73s 7ms/step - loss: 0.1652 - acc: 0.9312\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 75s 7ms/step - loss: 0.1482 - acc: 0.9422\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 74s 7ms/step - loss: 0.1238 - acc: 0.9516\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 74s 7ms/step - loss: 0.1357 - acc: 0.9464\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 75s 7ms/step - loss: 0.1150 - acc: 0.9579\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 75s 7ms/step - loss: 0.0845 - acc: 0.9694\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 76s 8ms/step - loss: 0.0788 - acc: 0.9713\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 75s 7ms/step - loss: 0.0662 - acc: 0.9763\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 75s 7ms/step - loss: 0.0603 - acc: 0.9782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5683f668>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_over.fit(X_over, Y_over, epochs=20, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train \"under\" Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 400, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 400, 64)           57664     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 200, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 200, 32)           6176      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 100, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 150)               480150    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 544,141\n",
      "Trainable params: 544,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "under_input = Input((max_words, n_word_vec))\n",
    "under_conv1 = Conv1D(64, 3, padding = \"same\", activation='relu')(under_input)\n",
    "under_pool1 = MaxPooling1D(pool_size=2)(under_conv1)\n",
    "under_conv2 = Conv1D(32, 3, padding = \"same\", activation='relu')(under_pool1)\n",
    "under_pool2 = MaxPooling1D(pool_size=2)(under_conv2)\n",
    "under_flatten = Flatten()(under_pool2)\n",
    "under_drop1 = Dropout(0.2)(under_flatten)\n",
    "under_dense1 = Dense(150, activation ='relu')(under_drop1)\n",
    "under_drop2 = Dropout(0.2)(under_dense1)\n",
    "under_out = Dense(1, activation ='sigmoid')(under_drop2)\n",
    "\n",
    "model_under = Model(inputs = under_input, outputs = under_out)\n",
    "model_under.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model_under.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 105s 11ms/step - loss: 0.5664 - acc: 0.6964\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 74s 7ms/step - loss: 0.4133 - acc: 0.8050\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 75s 7ms/step - loss: 0.3665 - acc: 0.8367\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 74s 7ms/step - loss: 0.3371 - acc: 0.8520\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 75s 7ms/step - loss: 0.2878 - acc: 0.8798\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 76s 8ms/step - loss: 0.2601 - acc: 0.8924\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 75s 7ms/step - loss: 0.2088 - acc: 0.9173\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 74s 7ms/step - loss: 0.1812 - acc: 0.9308\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 76s 8ms/step - loss: 0.1741 - acc: 0.9331\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 74s 7ms/step - loss: 0.1264 - acc: 0.9529\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 75s 7ms/step - loss: 0.1006 - acc: 0.9635\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 75s 7ms/step - loss: 0.0722 - acc: 0.9752\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 75s 7ms/step - loss: 0.0607 - acc: 0.9801\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 76s 8ms/step - loss: 0.0471 - acc: 0.9856\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 76s 8ms/step - loss: 0.0680 - acc: 0.9754\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 75s 8ms/step - loss: 0.0441 - acc: 0.9867\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 76s 8ms/step - loss: 0.0377 - acc: 0.9871\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 75s 8ms/step - loss: 0.0312 - acc: 0.9898\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 76s 8ms/step - loss: 0.0330 - acc: 0.9884\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 75s 7ms/step - loss: 0.0276 - acc: 0.9911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2888c5c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_under.fit(X_under, Y_under, epochs=20, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_over.save(\"CNN_over.h5\")\n",
    "model_under.save(\"CNN_under.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "\n",
    "We can now evaluate the performance on the three class classification problem. If both a review is classified both as \"under\" and \"over\" we interpret it as being neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(X_test, Y_test):\n",
    "    N_test = len(X_test)\n",
    "    Y_pred_over = np.reshape(np.round(model_over.predict(X_test)),(N_test,))\n",
    "    Y_pred_under = np.reshape(np.round(model_under.predict(X_test)),(N_test,))\n",
    "\n",
    "    Y_score = (Y_pred_over-Y_pred_under) - Y_test\n",
    "\n",
    "    acc = sum(1 for y in Y_score if y==0) / N_test\n",
    "    \n",
    "    print(\"Accuracy: \", str(round(100*acc))+\"%\")\n",
    "    \n",
    "    return(Y_pred_over, Y_pred_under, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  71%\n"
     ]
    }
   ],
   "source": [
    "Y_pred_over, Y_pred_under, acc = score_model(X_test,Y_test)\n",
    "Y_pred = (Y_pred_over-Y_pred_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have over 70% accuracy, which is pretty good! Additionally, we can look at the confusion matrix for this classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a55fed048>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmat= confusion_matrix(Y_test,Y_pred,labels=[1,0,-1])\n",
    "cmat_norm = [r/sum(r) for r in cmat]\n",
    "sns.heatmap(pd.DataFrame(cmat_norm,index=[1,0,-1], columns=[1,0,-1]), annot=True, cbar=False, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the classifier is very conservative about predict that reviews will be over the mean, which we made by design. The recall is quite low, although the precision is high. For reviews that are under the mean, the classifier does much better. Indeed if all we care about is predicting if a review will be \"too low,\" we have the following confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a28a845f8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmat_under = [[sum(cmat[:2,:2].flatten()), cmat[0,2]+cmat[1,2]],[cmat[2,0]+cmat[2,1], cmat[2,2]]]\n",
    "cmat_under_norm = [row/sum(row) for row in cmat_under]\n",
    "sns.heatmap(pd.DataFrame(cmat_under_norm,index=[0,-1], columns=[0,-1]), annot=True, cbar=False, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  85%\n"
     ]
    }
   ],
   "source": [
    "acc_under = sum(np.diagonal(cmat_under))/N_test\n",
    "print(\"Accuracy: \", str(int(round(100*acc_under)))+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is 85%, and again we see by design that the precision is very high. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can look at a histogram of true values versus predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Y_test,alpha=0.5, label = \"True\")\n",
    "plt.hist(Y_pred,alpha=0.5, label = \"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see we were a bit overzealous in keeping our false positive rates down, and so the classifier might do better with some further tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute a baseline for this problem, we consider the following general model for a multiclass problem. Let there be $n_1, n_2, \\cdots$ instances of each class in the test set with total number of instances $n$. A random guessing model could randomly order all the instances, then take the first $n_1$ to be class $1$, the next $n_2$ to be class $2$, etc. The expected number of instances classified correctly for class $i$ is given by $n_i * n_i/n$, as we choose $n_i$ random samples, each with probability $n_i/n$ of being class $i$. \n",
    "\n",
    "Therefore the total expected accuracy is given by \n",
    "$$\\text{acc} = \\frac1 n\\left({n_1^2/n + n_2^2 / n + \\cdots}\\right) = \\frac 1{n^2} \\left( n_1^2 + n_2^2 + \\cdots\\right)$$\n",
    "\n",
    "We can compute this for each of our classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50264114"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(cmat[k])**2 for k in range(3)) / N_test**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the three class problem our 71% accuracy is over 20% better than random guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63436928"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(cmat_under[k])**2 for k in range(2)) / sum(sum(cmat_under))**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For just classifying underrated reviews the 85% accuracy is also over 20% better than random guessing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
